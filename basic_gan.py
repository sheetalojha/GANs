# -*- coding: utf-8 -*-
"""Untitled20.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IDOEe2IGYHY39LdbNhmvDur8JJ9XdPdK
"""

#discriminator model
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
discriminator = keras.Sequential()
#downsample to 14x14
discriminator.add(layers.Conv2D(64
                                , (3, 3), strides = (2, 2), padding = 'same', input_shape = (28, 28, 3)))
discriminator.add(layers.LeakyReLU(alpha = 0.2))
discriminator.add(layers.BatchNormalization())
#downsample to 7x7
discriminator.add(layers.Conv2D(64, (3, 3), strides = (2, 2), padding = 'same'))
discriminator.add(layers.LeakyReLU(alpha = 0.2))
discriminator.add(layers.BatchNormalization())
#classify
discriminator.add(layers.Flatten())
discriminator.add(layers.Dense(1, activation = 'sigmoid'))
#complie model
opt = keras.optimizers.Adam(learning_rate=0.0002, beta_1 = 0.5)
discriminator.compile(loss = 'binary_crossentropy', optimizer = opt)

#generator model
generator = keras.Sequential()
n_nodes = 64 * 7 * 7
generator.add(layers.Dense(n_nodes, input_dim = 100))
generator.add(layers.LeakyReLU(alpha = 0.2))
generator.add(layers.BatchNormalization())
generator.add(layers.Reshape((7, 7, 64)))

#upsample to 14x14
generator.add(layers.Conv2DTranspose(64, (3,3), strides= (2,2), padding = 'same'))
generator.add(layers.LeakyReLU(alpha = 0.2))
generator.add(layers.BatchNormalization())
#upsample to 28x28
generator.add(layers.Conv2DTranspose(64, (3,3), strides = (2, 2), padding= 'same'))
generator.add(layers.LeakyReLU(alpha =0.2))
generator.add(layers.BatchNormalization())
generator.add(layers.Conv2D(3, (3,3), activation = 'tanh', padding = 'same'))

#composite model for training the generator via discriminator
#make weights in the discriminator model non - trainable
discriminator.trainable = False
model = keras.Sequential()
model.add(generator)
model.add(discriminator)
model.compile(loss = 'binary_crossentropy', optimizer=keras.optimizers.Adam(lr = 0.0002, beta_1 = 0.5))

